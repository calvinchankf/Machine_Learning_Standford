# Coursera Machine Learning Course By Andrew Ng

---

This course provides a broad introduction to machine learning, data mining, and statistical pattern recognition.

#### Topics include:

1. Supervised learning (parametric/non-parametric algorithms, support vector machines, kernels, neural networks).
1. Unsupervised learning (clustering, dimensionality reduction, recommender systems, deep learning).
1. Best practices in machine learning (bias/variance theory; innovation process in machine learning and AI).

The course also draws from numerous case studies and applications, enable students to apply learning algorithms to building smart robots (perception, control), text understanding (web search, anti-spam), computer vision, medical informatics, audio, database mining, and other areas.

#### week 1
- Introduction
- Linear Algebra review
- Linear regression with one variable

### week 2
- Linear Regression with multiple variables
- Octave Tutorial
- Assignment 1
  - Linear Regression with one variable
  - Linear Regression with multiple variables

### week 3
- Regularization to solve the problem of overfitting
- Logistic Regression
- Assignment 2
  - Logistic Regression
  - Regularization

### week 4
- Neural Networks Introduction
- Assignment 3
  - Multi-class Classification
  - Neural Networks(forward propagation)

### week 5
- Neural Networks in Detail ***(I think this is the most difficult concept in this course)***
- Assignment 4
  - Neural Networks cost function and back propagation
  ***(the assignment is also the most difficult; I spent a whole day for it)***

### week 6
- Bias(underfiting) vs Variance(overfiting)
- Error analysis
- Assignment 5
  - Regularized Linear Regression
  - Bias vs Variance

### week 7
- Support Vector Machines(SVM: A way to optimize decision boundaries)
- (Gaussian) Kernels(The mathematical implementation of SVM)
- Assignment 6
  - SVM
  - Kernels

### week 8
- Clustering (Unsupervised learning introduction)
- K-means Algorithm(A way to separate data into Clusters)
- Dimensionality Reduction ***(what a fancy name LOL)***
- Principal Component Analysis (A mathematical way to compress multi-dimension data in order to optimize training time)
- Data Reconstruction from compressed representation
- Assignment 7 ***(The 2nd most difficult asg, i was so confused to get started)***
  - K-means Clustering
  - Principal Component Analysis

### week 9
- Anomaly Detection using Gaussian distribution
- Recommender Systems (Content-based filtering, Collaborative
filtering)
- Assignment 8 ***(last asg)***
  - Anomaly Detection
  - Recommender Systems

### week 10
- Large scale machine learning (just a conceptual introduction)
  - Stochastic gradient descent
  - Mini-batch gradient descent
  - Online learning
  - Map-reduce and data parallelism

### week 11
- Optical character recognition on photos
  - Implementation pipeline
  - Sliding window
  - Ceiling Analysis

P.S. I did all the assignment in Octave

***Thank you Andrew Ng***
